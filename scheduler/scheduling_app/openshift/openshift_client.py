import logging
from abc import abstractmethod
from dataclasses import dataclass
from typing import List, Optional
from uuid import UUID

from kubernetes import client, config

from energy_calculator import KwhUsedAtReadTime
from utils.FileStates import PipelineProcessor

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class OpenshiftPod:
    """Represents a pod in openshift.

    Attributes:
        :param name: The name of the pod
        :param namespace: The namespace the pod is in
        :param pod_id: The id of the pod
        :param pod_identifier: The identifier of the pod, used to identify the
            pod by the scheduler to assign the correct files. This is a UUID
            generated by the scheduler when the pod is created.
        :param ip: The ip of the pod
        :param status: The status of the pod
        :param labels: The labels of the pod
    """

    name: str
    namespace: str
    pod_id: str
    pod_identifier: str
    ip: str
    status: str
    labels: dict


class OpenshiftClientInterface:
    @abstractmethod
    def __init__(self, namespace: str):
        raise NotImplementedError

    @abstractmethod
    def get_pods(
        self, processor: Optional[PipelineProcessor] = None
    ) -> List[OpenshiftPod]:
        raise NotImplementedError

    @abstractmethod
    def add_pods_for_pipeline_processor(
        self, number: int, processor: PipelineProcessor
    ) -> List[OpenshiftPod]:
        raise NotImplementedError

    @abstractmethod
    def scale_pipeline_processor(
        self, processor: PipelineProcessor, replicas: int
    ) -> List[OpenshiftPod]:
        raise NotImplementedError

    @abstractmethod
    def run_pod_for_processor(
        self, processor: PipelineProcessor, pod_identifier: UUID
    ) -> OpenshiftPod:
        raise NotImplementedError

    @abstractmethod
    def gather_pod_resource_consumption_statistics(
        self, pod: OpenshiftPod, metric_thread_result: list[KwhUsedAtReadTime]
    ):
        raise NotImplementedError

    @abstractmethod
    def delete_pod(self, pod: OpenshiftPod, force: bool):
        raise NotImplementedError


class OpenshiftClient(OpenshiftClientInterface):
    def __init__(self, namespace):
        self.namespace = namespace
        self.__load_config()
        self.core_v1_api = client.CoreV1Api()
        self.apps_v1_api = client.AppsV1Api()

    @staticmethod
    def __load_config():
        try:
            config.load_kube_config()
            logger.info("Using local kube config")
        except Exception:
            # load_kube_config throws if there is no config, but does not
            # document what it throws, can't rely on any particular type here
            config.load_incluster_config()
            logger.info("Using in-cluster kube config")

    def get_pods(
        self, processor: Optional[PipelineProcessor] = None
    ) -> List[OpenshiftPod]:
        logger.info("Getting pods for %s", processor)

        if processor is not None:
            # TODO: filter by processor
            raise NotImplementedError()

        ret = self.core_v1_api.list_namespaced_pod(
            namespace=self.namespace, watch=False
        )

        # TODO: Add pod_identifier
        return [
            OpenshiftPod(
                name=item.metadata.name,
                namespace=item.metadata.namespace,
                pod_id=item.metadata.uid,
                ip=item.status.pod_ip,
                status=item.status.phase,
                labels=item.metadata.labels,
            )
            for item in ret.items
        ]

    def scale_pipeline_processor(
        self, processor: PipelineProcessor, replicas
    ) -> List[OpenshiftPod]:
        logger.info("Scaling %s to %i replicas", processor, replicas)
        self.apps_v1_api.patch_namespaced_deployment_scale(
            name=processor.code,
            namespace=self.namespace,
            body={"spec": {"replicas": replicas}},
        )

        return self.get_pods(None)
